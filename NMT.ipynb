{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"NMT.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"Ti2QKGsrIm5p","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1614567576526,"user_tz":-420,"elapsed":27323,"user":{"displayName":"huy dang","photoUrl":"","userId":"13802926353885973369"}},"outputId":"7202223d-a248-4dcf-9b97-aee9611c7be1"},"source":["### Restart runtime after installation\r\n","! pip install -q google-cloud-speech\r\n","! pip install -q --upgrade google-cloud-translate\r\n","! pip -q install torchtext==0.6.0\r\n","! pip -q install pyvi \r\n","! pip -q install ffmpeg-python\r\n"],"execution_count":1,"outputs":[{"output_type":"stream","text":["\u001b[?25l\r\u001b[K     |███                             | 10kB 24.8MB/s eta 0:00:01\r\u001b[K     |██████                          | 20kB 18.4MB/s eta 0:00:01\r\u001b[K     |█████████                       | 30kB 13.6MB/s eta 0:00:01\r\u001b[K     |████████████                    | 40kB 13.3MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 51kB 8.5MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 61kB 7.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 71kB 8.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 81kB 9.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 92kB 9.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 102kB 9.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 112kB 9.3MB/s \n","\u001b[K     |████████████████████████████████| 102kB 8.4MB/s \n","\u001b[K     |████████████████████████████████| 512kB 8.9MB/s \n","\u001b[K     |████████████████████████████████| 51kB 9.0MB/s \n","\u001b[K     |████████████████████████████████| 645kB 16.9MB/s \n","\u001b[K     |████████████████████████████████| 102kB 6.6MB/s \n","\u001b[K     |████████████████████████████████| 71kB 5.3MB/s \n","\u001b[K     |████████████████████████████████| 1.2MB 7.6MB/s \n","\u001b[K     |████████████████████████████████| 8.5MB 4.0MB/s \n","\u001b[K     |████████████████████████████████| 747kB 53.5MB/s \n","\u001b[?25h"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"faXDW84iIxbt","executionInfo":{"status":"ok","timestamp":1614567713028,"user_tz":-420,"elapsed":809,"user":{"displayName":"huy dang","photoUrl":"","userId":"13802926353885973369"}},"outputId":"ce3bfd29-14a4-44dc-8cbc-0fb591db005e"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"w_CnZNbZ0luZ","executionInfo":{"status":"ok","timestamp":1614567723369,"user_tz":-420,"elapsed":8478,"user":{"displayName":"huy dang","photoUrl":"","userId":"13802926353885973369"}},"outputId":"bea85ef3-6564-49ef-d44e-a5d27c8fdaa8"},"source":["%cd /content/drive/MyDrive/NLP_project\r\n","! pip -q install './model/vi_spacy_model-0.2.1.tar.gz'\r\n","! python -m spacy link vi_spacy_model vi_spacy_model\r\n"],"execution_count":2,"outputs":[{"output_type":"stream","text":["/content/drive/.shortcut-targets-by-id/1kWFkPboOT_MgvjCmTkgRnw2lbnQb8HPw/NLP_project\n","  Building wheel for vi-spacy-model (setup.py) ... \u001b[?25l\u001b[?25hdone\n","\n","\u001b[38;5;1m✘ Link 'vi_spacy_model' already exists\u001b[0m\n","To overwrite an existing link, use the --force flag\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wT_eDvnB0Ggd","executionInfo":{"status":"ok","timestamp":1614567725314,"user_tz":-420,"elapsed":8872,"user":{"displayName":"huy dang","photoUrl":"","userId":"13802926353885973369"}},"outputId":"3bd61338-37e1-455b-c314-cbfb68745b6f"},"source":["from src.transformer import *\r\n","from src.s2t import * \r\n"],"execution_count":3,"outputs":[{"output_type":"stream","text":["[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data]   Package wordnet is already up-to-date!\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"uW35UQVz5AuE","executionInfo":{"status":"ok","timestamp":1614567729422,"user_tz":-420,"elapsed":982,"user":{"displayName":"huy dang","photoUrl":"","userId":"13802926353885973369"}}},"source":["set_key()"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RWF_155tsbpA","executionInfo":{"status":"ok","timestamp":1614506168627,"user_tz":-420,"elapsed":693,"user":{"displayName":"huy dang","photoUrl":"","userId":"13802926353885973369"}},"outputId":"6d644bd2-1413-4414-ad2c-d01b5a9310d7"},"source":["print(opt['train_src_data'], opt['train_trg_data'])\r\n","#opt['train_src_data'] = './data/train_2/train.en'\r\n","#opt['train_trg_data'] = './data/train_2/train.vi'\r\n","#opt['n_layers'] =6 \r\n","print(opt['train_src_data'])\r\n","print(opt['train_trg_data'])\r\n","print(opt['n_layers'])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["./data/train_2/train.en ./data/train_2/train.vi\n","./data/train_2/train.en\n","./data/train_2/train.vi\n","6\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Qaw6VUPDzJ8j","executionInfo":{"status":"ok","timestamp":1614567835392,"user_tz":-420,"elapsed":87928,"user":{"displayName":"huy dang","photoUrl":"","userId":"13802926353885973369"}},"outputId":"055f5bf2-9972-4eb4-e021-b59181487372"},"source":["\r\n","train_src_data, train_trg_data = read_data(opt['train_src_data'], opt['train_trg_data'])\r\n","valid_src_data, valid_trg_data = read_data(opt['valid_src_data'], opt['valid_trg_data'])\r\n","\r\n","SRC, TRG = create_fields(opt['src_lang'], opt['trg_lang'])\r\n","train_iter = create_dataset(train_src_data, train_trg_data, opt['max_strlen'], opt['batchsize'], opt['device'], SRC, TRG, istrain=True)\r\n","valid_iter = create_dataset(valid_src_data, valid_trg_data, opt['max_strlen'], opt['batchsize'], opt['device'], SRC, TRG, istrain=False)\r\n","\r\n","src_pad = SRC.vocab.stoi['<pad>']\r\n","trg_pad = TRG.vocab.stoi['<pad>']\r\n","\r\n","model = Transformer(len(SRC.vocab), len(TRG.vocab), opt['d_model'], opt['n_layers'], opt['heads'], opt['dropout'])\r\n","\r\n","for p in model.parameters():\r\n","    if p.dim() > 1:\r\n","        nn.init.xavier_uniform_(p)\r\n","\r\n","model = model.to(opt['device'])\r\n","\r\n","optimizer = ScheduledOptim(\r\n","        torch.optim.Adam(model.parameters(), betas=(0.9, 0.98), eps=1e-09),\r\n","        0.2, opt['d_model'], 4000)\r\n","\r\n","criterion = LabelSmoothingLoss(len(TRG.vocab), padding_idx=trg_pad, smoothing=0.1)\r\n"],"execution_count":5,"outputs":[{"output_type":"stream","text":["loading spacy tokenizers...\n","creating dataset and iterator... \n","creating dataset and iterator... \n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Yh303PENFaDM"},"source":["import pickle\r\n","f = open('SRC.pkl', 'wb')\r\n","pickle.dump(SRC, f)\r\n","f.close()\r\n","\r\n","f = open('TRG.pkl', 'wb')\r\n","pickle.dump(TRG, f)\r\n","f.close()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PAHG3wB0Ctxl"},"source":["def train_precheck():\r\n","    train_dict_path = os.path.join('model','tsd.json')\r\n","    if os.path.exists(train_dict_path):\r\n","        with open(train_dict_path, 'r') as fp:\r\n","            train_state_dict = json.load(fp)\r\n","        model.load_state_dict(torch.load(train_state_dict['last_weight']))\r\n","        \r\n","    else:  \r\n","        train_state_dict = {\r\n","            'epoch' : 0,\r\n","            'bluescore' : 0,\r\n","            'last_weight' : '' \r\n","        }\r\n","    \r\n","    return train_state_dict"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Dby16ZmVWyOY","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1614506651198,"user_tz":-420,"elapsed":5503,"user":{"displayName":"huy dang","photoUrl":"","userId":"13802926353885973369"}},"outputId":"1e8266fd-f698-495e-e07c-898c832f628c"},"source":["train_state_dict = train_precheck()\r\n","train_state_dict"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'bluescore': 0, 'epoch': 15, 'last_weight': 'model/transformer15.pth'}"]},"metadata":{"tags":[]},"execution_count":11}]},{"cell_type":"code","metadata":{"id":"5GBnKQFb7eJf","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"error","timestamp":1614525020265,"user_tz":-420,"elapsed":18334374,"user":{"displayName":"huy dang","photoUrl":"","userId":"13802926353885973369"}},"outputId":"2f264dcc-a2e3-462d-dbb3-648ef27b491d"},"source":["import time\r\n","\r\n","train = 1\r\n","\r\n","if train == 1:\r\n","    train_state_dict = train_precheck()\r\n","    oldbleu = train_state_dict['bluescore']\r\n","    epoch = train_state_dict['epoch']\r\n","    #epoch = 8\r\n","    bleuscore = 0\r\n","    while epoch < opt['epochs']:\r\n","        total_loss = 0\r\n","        \r\n","        for i, batch in enumerate(train_iter): \r\n","            s = time.time()\r\n","            loss = step(model, optimizer, batch, criterion, src_pad, trg_pad)\r\n","            \r\n","            total_loss += loss\r\n","            \r\n","            if (i + 1) % opt['printevery'] == 0:\r\n","                avg_loss = total_loss/opt['printevery']\r\n","                print('epoch: {:03d} - iter: {:05d} - train loss: {:.4f} - time: {:.4f}'.format(epoch+1, i, avg_loss, time.time()- s))\r\n","                total_loss = 0\r\n","\r\n","        s = time.time()\r\n","        valid_loss = validate(model, valid_iter, criterion, src_pad, trg_pad)\r\n","        \r\n","        oldbleu = bleuscore\r\n","        if epoch > 20:\r\n","            bleuscore = bleu(valid_src_data[:300], valid_trg_data[:300], model, SRC, TRG, opt['device'], opt['k'], opt['max_strlen'])\r\n","        print('epoch: {:03d} - iter: {:05d} - valid loss: {:.4f} - bleu score: {:.4f} - time: {:.4f}'.format(epoch+1, i, valid_loss, bleuscore, time.time() - s))\r\n","        \r\n","        \r\n","        if epoch % 5 == 0 and epoch >= 10:\r\n","            torch.save(model.state_dict(), os.path.join('model','transformer'+str(epoch)+'.pth'))\r\n","            train_state_dict['epoch'] = epoch\r\n","            train_state_dict['last_weight'] =os.path.join('model','transformer'+str(epoch)+'.pth')\r\n","            train_state_dict['bluescore'] = bleuscore\r\n","            with open( os.path.join('model', 'tsd.json'), 'w') as fp:\r\n","                json.dump(train_state_dict, fp, sort_keys=True, indent=4)\r\n","\r\n","        if bleuscore > oldbleu:\r\n","            torch.save(model.state_dict(), os.path.join('model', 'bestaug.pth'))\r\n","        epoch += 1"],"execution_count":null,"outputs":[{"output_type":"stream","text":["epoch: 016 - iter: 00499 - train loss: 2.6733 - time: 0.2435\n","epoch: 016 - iter: 00999 - train loss: 2.6618 - time: 0.2332\n","epoch: 016 - iter: 01499 - train loss: 2.6906 - time: 0.2601\n","epoch: 016 - iter: 01999 - train loss: 2.7219 - time: 0.2480\n","epoch: 016 - iter: 02499 - train loss: 2.7433 - time: 0.2556\n","epoch: 016 - iter: 02999 - train loss: 2.7728 - time: 0.2421\n","epoch: 016 - iter: 03499 - train loss: 2.7571 - time: 0.2510\n","epoch: 016 - iter: 03999 - train loss: 2.7794 - time: 0.2509\n","epoch: 016 - iter: 04385 - valid loss: 2.3358 - bleu score: 0.0000 - time: 2.6006\n","epoch: 017 - iter: 00499 - train loss: 2.7696 - time: 0.2658\n","epoch: 017 - iter: 00999 - train loss: 2.7956 - time: 0.2693\n","epoch: 017 - iter: 01499 - train loss: 2.7878 - time: 0.2733\n","epoch: 017 - iter: 01999 - train loss: 2.8237 - time: 0.2527\n","epoch: 017 - iter: 02499 - train loss: 2.8246 - time: 0.2549\n","epoch: 017 - iter: 02999 - train loss: 2.8157 - time: 0.2645\n","epoch: 017 - iter: 03499 - train loss: 2.7435 - time: 0.2626\n","epoch: 017 - iter: 03999 - train loss: 2.7692 - time: 0.2552\n","epoch: 017 - iter: 04385 - valid loss: 2.3016 - bleu score: 0.0000 - time: 2.5910\n","epoch: 018 - iter: 00499 - train loss: 2.6770 - time: 0.2494\n","epoch: 018 - iter: 00999 - train loss: 2.7039 - time: 0.2520\n","epoch: 018 - iter: 01499 - train loss: 2.7267 - time: 0.2325\n","epoch: 018 - iter: 01999 - train loss: 2.7196 - time: 0.2427\n","epoch: 018 - iter: 02499 - train loss: 2.7214 - time: 0.2410\n","epoch: 018 - iter: 02999 - train loss: 2.7316 - time: 0.2486\n","epoch: 018 - iter: 03499 - train loss: 2.6689 - time: 0.2510\n","epoch: 018 - iter: 03999 - train loss: 2.6640 - time: 0.2487\n","epoch: 018 - iter: 04390 - valid loss: 2.2857 - bleu score: 0.0000 - time: 2.6002\n","epoch: 019 - iter: 00499 - train loss: 2.6262 - time: 0.2583\n","epoch: 019 - iter: 00999 - train loss: 2.6139 - time: 0.2647\n","epoch: 019 - iter: 01499 - train loss: 2.6666 - time: 0.2537\n","epoch: 019 - iter: 01999 - train loss: 2.6575 - time: 0.2480\n","epoch: 019 - iter: 02499 - train loss: 2.6582 - time: 0.2435\n","epoch: 019 - iter: 02999 - train loss: 2.6817 - time: 0.2437\n","epoch: 019 - iter: 03499 - train loss: 2.6096 - time: 0.2505\n","epoch: 019 - iter: 03999 - train loss: 2.6221 - time: 0.2040\n","epoch: 019 - iter: 04391 - valid loss: 2.2897 - bleu score: 0.0000 - time: 2.5866\n","epoch: 020 - iter: 00499 - train loss: 2.5879 - time: 0.2495\n","epoch: 020 - iter: 00999 - train loss: 2.6000 - time: 0.2237\n","epoch: 020 - iter: 01499 - train loss: 2.6005 - time: 0.2581\n","epoch: 020 - iter: 01999 - train loss: 2.6136 - time: 0.2372\n","epoch: 020 - iter: 02499 - train loss: 2.6209 - time: 0.2555\n","epoch: 020 - iter: 02999 - train loss: 2.6274 - time: 0.2724\n","epoch: 020 - iter: 03499 - train loss: 2.5773 - time: 0.2502\n","epoch: 020 - iter: 03999 - train loss: 2.5593 - time: 0.2523\n","epoch: 020 - iter: 04385 - valid loss: 2.2840 - bleu score: 0.0000 - time: 2.5902\n","epoch: 021 - iter: 00499 - train loss: 2.5647 - time: 0.2541\n","epoch: 021 - iter: 00999 - train loss: 2.5695 - time: 0.2535\n","epoch: 021 - iter: 01499 - train loss: 2.5707 - time: 0.2684\n","epoch: 021 - iter: 01999 - train loss: 2.5653 - time: 0.2566\n","epoch: 021 - iter: 02499 - train loss: 2.5716 - time: 0.2532\n","epoch: 021 - iter: 02999 - train loss: 2.5722 - time: 0.2511\n","epoch: 021 - iter: 03499 - train loss: 2.5222 - time: 0.2486\n","epoch: 021 - iter: 03999 - train loss: 2.5335 - time: 0.2486\n","epoch: 021 - iter: 04389 - valid loss: 2.2872 - bleu score: 0.0000 - time: 2.5849\n","epoch: 022 - iter: 00499 - train loss: 2.5307 - time: 0.2530\n","epoch: 022 - iter: 00999 - train loss: 2.5243 - time: 0.2551\n","epoch: 022 - iter: 01499 - train loss: 2.5378 - time: 0.2562\n","epoch: 022 - iter: 01999 - train loss: 2.5440 - time: 0.2524\n","epoch: 022 - iter: 02499 - train loss: 2.5418 - time: 0.2321\n","epoch: 022 - iter: 02999 - train loss: 2.5572 - time: 0.2706\n","epoch: 022 - iter: 03499 - train loss: 2.5139 - time: 0.2464\n","epoch: 022 - iter: 03999 - train loss: 2.4931 - time: 0.2589\n"],"name":"stdout"},{"output_type":"stream","text":["/content/drive/.shortcut-targets-by-id/1kWFkPboOT_MgvjCmTkgRnw2lbnQb8HPw/NLP_project/src/transformer.py:486: UserWarning: This overload of nonzero is deprecated:\n","\tnonzero()\n","Consider using one of the following signatures instead:\n","\tnonzero(*, bool as_tuple) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:882.)\n","  ones = (outputs==eos_tok).nonzero() # Occurrences of end symbols for all input sentences.\n"],"name":"stderr"},{"output_type":"stream","text":["epoch: 022 - iter: 04386 - valid loss: 2.2862 - bleu score: 0.2794 - time: 147.5228\n","epoch: 023 - iter: 00499 - train loss: 2.4934 - time: 0.2505\n","epoch: 023 - iter: 00999 - train loss: 2.4975 - time: 0.2732\n","epoch: 023 - iter: 01499 - train loss: 2.5114 - time: 0.2647\n","epoch: 023 - iter: 01999 - train loss: 2.5097 - time: 0.2550\n","epoch: 023 - iter: 02499 - train loss: 2.5306 - time: 0.2566\n","epoch: 023 - iter: 02999 - train loss: 2.5225 - time: 0.2560\n","epoch: 023 - iter: 03499 - train loss: 2.4871 - time: 0.2729\n","epoch: 023 - iter: 03999 - train loss: 2.4683 - time: 0.2517\n","epoch: 023 - iter: 04389 - valid loss: 2.2900 - bleu score: 0.2784 - time: 147.2766\n","epoch: 024 - iter: 00499 - train loss: 2.4638 - time: 0.2519\n","epoch: 024 - iter: 00999 - train loss: 2.4833 - time: 0.2544\n","epoch: 024 - iter: 01499 - train loss: 2.4865 - time: 0.2498\n","epoch: 024 - iter: 01999 - train loss: 2.4867 - time: 0.2674\n","epoch: 024 - iter: 02499 - train loss: 2.4859 - time: 0.2428\n","epoch: 024 - iter: 02999 - train loss: 2.5027 - time: 0.2508\n","epoch: 024 - iter: 03499 - train loss: 2.4733 - time: 0.2374\n","epoch: 024 - iter: 03999 - train loss: 2.4464 - time: 0.2457\n","epoch: 024 - iter: 04388 - valid loss: 2.2932 - bleu score: 0.2750 - time: 146.5800\n","epoch: 025 - iter: 00499 - train loss: 2.4336 - time: 0.2465\n","epoch: 025 - iter: 00999 - train loss: 2.4697 - time: 0.2516\n","epoch: 025 - iter: 01499 - train loss: 2.4581 - time: 0.2632\n","epoch: 025 - iter: 01999 - train loss: 2.4668 - time: 0.2521\n","epoch: 025 - iter: 02499 - train loss: 2.4879 - time: 0.2774\n","epoch: 025 - iter: 02999 - train loss: 2.4692 - time: 0.2655\n","epoch: 025 - iter: 03499 - train loss: 2.4388 - time: 0.2429\n","epoch: 025 - iter: 03999 - train loss: 2.4334 - time: 0.2518\n","epoch: 025 - iter: 04389 - valid loss: 2.3000 - bleu score: 0.2777 - time: 148.0672\n","epoch: 026 - iter: 00499 - train loss: 2.4405 - time: 0.2694\n","epoch: 026 - iter: 00999 - train loss: 2.4391 - time: 0.2216\n","epoch: 026 - iter: 01499 - train loss: 2.4366 - time: 0.2582\n","epoch: 026 - iter: 01999 - train loss: 2.4547 - time: 0.2531\n","epoch: 026 - iter: 02499 - train loss: 2.4456 - time: 0.2683\n","epoch: 026 - iter: 02999 - train loss: 2.4424 - time: 0.2483\n","epoch: 026 - iter: 03499 - train loss: 2.4077 - time: 0.2514\n","epoch: 026 - iter: 03999 - train loss: 2.4144 - time: 0.2472\n","epoch: 026 - iter: 04390 - valid loss: 2.3025 - bleu score: 0.2706 - time: 144.8431\n","epoch: 027 - iter: 00499 - train loss: 2.4020 - time: 0.2422\n","epoch: 027 - iter: 00999 - train loss: 2.4125 - time: 0.2473\n","epoch: 027 - iter: 01499 - train loss: 2.4370 - time: 0.2599\n","epoch: 027 - iter: 01999 - train loss: 2.4371 - time: 0.2741\n","epoch: 027 - iter: 02499 - train loss: 2.4316 - time: 0.2513\n","epoch: 027 - iter: 02999 - train loss: 2.4296 - time: 0.2491\n","epoch: 027 - iter: 03499 - train loss: 2.3921 - time: 0.2639\n","epoch: 027 - iter: 03999 - train loss: 2.4076 - time: 0.2562\n","epoch: 027 - iter: 04388 - valid loss: 2.3134 - bleu score: 0.2771 - time: 143.4166\n","epoch: 028 - iter: 00499 - train loss: 2.3799 - time: 0.2509\n","epoch: 028 - iter: 00999 - train loss: 2.3978 - time: 0.2556\n","epoch: 028 - iter: 01499 - train loss: 2.4107 - time: 0.2488\n","epoch: 028 - iter: 01999 - train loss: 2.4178 - time: 0.2566\n","epoch: 028 - iter: 02499 - train loss: 2.4154 - time: 0.2440\n","epoch: 028 - iter: 02999 - train loss: 2.4258 - time: 0.2572\n","epoch: 028 - iter: 03499 - train loss: 2.3831 - time: 0.2482\n","epoch: 028 - iter: 03999 - train loss: 2.3828 - time: 0.2530\n","epoch: 028 - iter: 04383 - valid loss: 2.3138 - bleu score: 0.2771 - time: 145.0991\n","epoch: 029 - iter: 00499 - train loss: 2.3766 - time: 0.2511\n","epoch: 029 - iter: 00999 - train loss: 2.3843 - time: 0.2554\n","epoch: 029 - iter: 01499 - train loss: 2.3869 - time: 0.2582\n","epoch: 029 - iter: 01999 - train loss: 2.3800 - time: 0.2567\n","epoch: 029 - iter: 02499 - train loss: 2.4036 - time: 0.2711\n","epoch: 029 - iter: 02999 - train loss: 2.4156 - time: 0.2544\n","epoch: 029 - iter: 03499 - train loss: 2.3488 - time: 0.2572\n","epoch: 029 - iter: 03999 - train loss: 2.3817 - time: 0.2564\n","epoch: 029 - iter: 04388 - valid loss: 2.3182 - bleu score: 0.2706 - time: 143.0539\n","epoch: 030 - iter: 00499 - train loss: 2.3702 - time: 0.2603\n","epoch: 030 - iter: 00999 - train loss: 2.3565 - time: 0.2520\n","epoch: 030 - iter: 01499 - train loss: 2.3794 - time: 0.2509\n","epoch: 030 - iter: 01999 - train loss: 2.3788 - time: 0.2482\n","epoch: 030 - iter: 02499 - train loss: 2.3848 - time: 0.2389\n","epoch: 030 - iter: 02999 - train loss: 2.4015 - time: 0.2534\n","epoch: 030 - iter: 03499 - train loss: 2.3413 - time: 0.2527\n","epoch: 030 - iter: 03999 - train loss: 2.3568 - time: 0.2580\n","epoch: 030 - iter: 04389 - valid loss: 2.3206 - bleu score: 0.2703 - time: 143.2329\n","epoch: 031 - iter: 00499 - train loss: 2.3456 - time: 0.2586\n"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-12-fa79b64f5a1b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc_pad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrg_pad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0mtotal_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/drive/.shortcut-targets-by-id/1kWFkPboOT_MgvjCmTkgRnw2lbnQb8HPw/NLP_project/src/transformer.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(model, optimizer, batch, criterion, src_pad, trg_pad)\u001b[0m\n\u001b[1;32m    618\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_and_update_lr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m                 create_graph=create_graph)\n\u001b[0;32m--> 221\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m    130\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    131\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"id":"ubfbbeeK6jot","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1614567865921,"user_tz":-420,"elapsed":4494,"user":{"displayName":"huy dang","photoUrl":"","userId":"13802926353885973369"}},"outputId":"dee3fc35-9985-4e71-9ce5-1a84351668c4"},"source":["model.load_state_dict(torch.load('./model/bestaug.pth'))"],"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<All keys matched successfully>"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"code","metadata":{"id":"c-tTHla_tuv5","colab":{"base_uri":"https://localhost:8080/","height":183},"executionInfo":{"status":"ok","timestamp":1614569702251,"user_tz":-420,"elapsed":16160,"user":{"displayName":"huy dang","photoUrl":"","userId":"13802926353885973369"}},"outputId":"a82ceff3-9bd9-481b-f7ac-8642b354baba"},"source":["import time\r\n","input = r_and_t()\r\n","start = time.time()\r\n","trans_sent = translate_sentence(input, model, SRC, TRG, opt['device'], opt['k'], opt['max_strlen'])\r\n","end = time.time()\r\n","response_gtrans = google_trans(input)\r\n","sent_gtrans = response_gtrans['translatedText']\r\n","\r\n","\r\n","print('Input: ', input)\r\n","print('Model predicted: ',trans_sent)\r\n","print('Google translated: ', sent_gtrans )\r\n","print('Time taken: {0}s with score of {1}'.format(round(end-start,4), 0))\r\n","print()"],"execution_count":11,"outputs":[{"output_type":"display_data","data":{"text/html":["\n","<script>\n","var my_div = document.createElement(\"DIV\");\n","var my_p = document.createElement(\"P\");\n","var my_btn = document.createElement(\"BUTTON\");\n","var t = document.createTextNode(\"Press to start recording\");\n","\n","my_btn.appendChild(t);\n","//my_p.appendChild(my_btn);\n","my_div.appendChild(my_btn);\n","document.body.appendChild(my_div);\n","\n","var base64data = 0;\n","var reader;\n","var recorder, gumStream;\n","var recordButton = my_btn;\n","\n","var handleSuccess = function(stream) {\n","  gumStream = stream;\n","  var options = {\n","    //bitsPerSecond: 8000, //chrome seems to ignore, always 48k\n","    mimeType : 'audio/webm;codecs=opus'\n","    //mimeType : 'audio/webm;codecs=pcm'\n","  };            \n","  //recorder = new MediaRecorder(stream, options);\n","  recorder = new MediaRecorder(stream);\n","  recorder.ondataavailable = function(e) {            \n","    var url = URL.createObjectURL(e.data);\n","    var preview = document.createElement('audio');\n","    preview.controls = true;\n","    preview.src = url;\n","    document.body.appendChild(preview);\n","\n","    reader = new FileReader();\n","    reader.readAsDataURL(e.data); \n","    reader.onloadend = function() {\n","      base64data = reader.result;\n","      //console.log(\"Inside FileReader:\" + base64data);\n","    }\n","  };\n","  recorder.start();\n","  };\n","\n","recordButton.innerText = \"Recording... press to stop\";\n","\n","navigator.mediaDevices.getUserMedia({audio: true}).then(handleSuccess);\n","\n","\n","function toggleRecording() {\n","  if (recorder && recorder.state == \"recording\") {\n","      recorder.stop();\n","      gumStream.getAudioTracks()[0].stop();\n","      recordButton.innerText = \"Saving...\"\n","  }\n","}\n","\n","// https://stackoverflow.com/a/951057\n","function sleep(ms) {\n","  return new Promise(resolve => setTimeout(resolve, ms));\n","}\n","\n","var data = new Promise(resolve=>{\n","//recordButton.addEventListener(\"click\", toggleRecording);\n","recordButton.onclick = ()=>{\n","toggleRecording()\n","\n","sleep(2000).then(() => {\n","  // wait 2000ms for the data to be available...\n","  // ideally this should use something like await...\n","  //console.log(\"Inside data:\" + base64data)\n","  resolve(base64data.toString())\n","\n","});\n","\n","}\n","});\n","      \n","</script>\n"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Input:  phone cases have been detected in England\n","Model predicted:  các trường hợp điện thoại được phát hiện ở anh\n","Google translated:  trường hợp điện thoại đã được phát hiện ở Anh\n","Time taken: 0.1926s with score of 0\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"KYqE0S-y6oxx","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1614526656176,"user_tz":-420,"elapsed":583500,"user":{"displayName":"huy dang","photoUrl":"","userId":"13802926353885973369"}},"outputId":"477dee63-fceb-4cdd-f3ab-7feb46240bee"},"source":["bleu(valid_src_data, valid_trg_data, model, SRC, TRG, opt['device'], opt['k'], opt['max_strlen'])"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.2697679102420807"]},"metadata":{"tags":[]},"execution_count":19}]},{"cell_type":"code","metadata":{"id":"zAviNaSGg7hj"},"source":["with open('data/tst2013.en') as f:\r\n","    train_en = f.readlines()\r\n","\r\n","with open('data/tst2013.vi') as f:\r\n","    train_vi = f.readlines()\r\n","\r\n","\r\n","\r\n","        \r\n","resu = []\r\n","for sent in train_en:\r\n","    r = google_trans(sent) \r\n","    resu.append(r['translatedText'])\r\n","\r\n","\r\n","google_bleu_score(resu, train_vi)\r\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"IFuavn4To-ow"},"source":["### based-line score 0.2569\r\n","#### Google scores: 0.3169"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZFi9_tb1wKtN"},"source":["mtrans = []\r\n","for sent in train_en:\r\n","    trans_sent = translate_sentence(sent, model, SRC, TRG, opt['device'], opt['k'], opt['max_strlen'])    \r\n","    mtrans.append(trans_sent)\r\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Nv8ZIbYYw_pi"},"source":["\r\n","bleu_google(resu, train_vi)\r\n"],"execution_count":null,"outputs":[]}]}